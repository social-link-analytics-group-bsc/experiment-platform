{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba47e2-d386-4b70-a221-03ecbc6aa9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "\n",
    "\n",
    "from textwrap import wrap\n",
    "import itertools \n",
    "from itertools import combinations\n",
    "\n",
    "# Classic analysis imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "# Stat analysis import \n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "import scipy \n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.stattools as stools\n",
    "\n",
    "import statsmodels.stats as stats \n",
    "\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from statsmodels.stats import multicomp as mc\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "#from pymer4.models import Lmer\n",
    "\n",
    "#import pingouin as pg\n",
    "\n",
    "# options for the notebook\n",
    "pd.set_option('display.max_colwidth',1000)\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "#%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da361e-136f-4e9f-8c54-128b36f5281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import norm\n",
    "def chisq_posthoc_corrected(cross_table, correction_method='bonferroni', alpha=.05):\n",
    "    \"\"\"\n",
    "    Get crosstab dataframe and do a chisquared test followed with the post-hoc with analysis of adjusted residuals\n",
    "    source: https://colab.research.google.com/drive/1QIDHMvpDq7Max5hk2mozSFdVssavdV-I#scrollTo=ig1kdg40qLDH\n",
    "    source: https://github.com/neuhofmo/chisq_test_wrapper\n",
    "    \"\"\"\n",
    "    def get_asterisks_for_pval(p_val, alpha=0.05):\n",
    "        \"\"\"Receives the p-value and returns asterisks string.\"\"\"\n",
    "        if p_val > alpha:  # bigger than alpha\n",
    "            p_text = \"ns\"\n",
    "        # following the standards in biological publications\n",
    "        elif p_val < 1e-4:  \n",
    "            p_text = '****'\n",
    "        elif p_val < 1e-3:\n",
    "            p_text = '***'\n",
    "        elif p_val < 1e-2:\n",
    "            p_text = '**'\n",
    "        else:\n",
    "            p_text = '*'\n",
    "    \n",
    "        return p_text  # string of asterisks\n",
    "    \n",
    "    chiVal, pVal, df, exp = chi2_contingency(cross_table)\n",
    "\n",
    "    colTotals = cross_table.sum()\n",
    "    nCols = len(colTotals)\n",
    "    rowTotals = cross_table.sum(axis=1)\n",
    "    nRows = len(rowTotals)\n",
    "    n = sum(rowTotals)\n",
    "    print(\"Chi2 result of the contingency table: {}, p-value: {}, dof: {}, N: {}\\n\".format(chiVal, pVal, df, n))\n",
    "\n",
    "    \n",
    "    for i in range(nRows):\n",
    "        for j in range(nCols):\n",
    "            AdjRes = (cross_table.iloc[i,j] - exp[i,j]) / (exp[i,j]*(1-rowTotals[i]/n)*(1-colTotals[j]/n))**0.5            \n",
    "    phRes = pd.DataFrame(columns=[cross_table.index.name, cross_table.columns.name, 'Adj. Res.'])\n",
    "    for i in range(nRows):\n",
    "        for j in range(nCols):\n",
    "            AdjRes = (cross_table.iloc[i,j] - exp[i,j]) / (exp[i,j]*(1-rowTotals[i]/n)*(1-colTotals[j]/n))**0.5\n",
    "            phRes = phRes.append({cross_table.index.name:cross_table.index[i], cross_table.columns.name:cross_table.columns[j], 'Adj. Res.':AdjRes}, ignore_index=True)\n",
    "    phRes['p_value'] = 2*(1-norm.cdf(abs(phRes['Adj. Res.'])))\n",
    "    # Bonferroni correction\n",
    "  \n",
    "    reject_list, corrected_p_vals = multipletests(phRes['p_value'], method=correction_method, alpha=alpha)[:2]\n",
    "    \n",
    "    phRes['p_value_corrected'] = corrected_p_vals\n",
    "    phRes['reject'] = reject_list\n",
    "    ast = []\n",
    "    for p_vals in corrected_p_vals:\n",
    "        ast.append(get_asterisks_for_pval(p_vals))\n",
    "    phRes['asterisques'] = ast\n",
    "\n",
    "    return phRes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cc14f-eec4-4dcd-a1f9-830a0f15700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://medium.com/analytics-vidhya/create-your-own-coefficient-plot-function-in-python-aadb9fe27a77\n",
    "# Define function to output plot of the model coefficients\n",
    "\n",
    "def coefplot(results):\n",
    "    '''\n",
    "    Takes in results of OLS model and returns a plot of \n",
    "    the coefficients with 95% confidence intervals.\n",
    "    \n",
    "    Removes intercept, so if uncentered will return error.\n",
    "    '''\n",
    "    # Create dataframe of results summary \n",
    "    coef_df = pd.DataFrame(results.summary().tables[1].data)\n",
    "    \n",
    "    # Add column names\n",
    "    coef_df.columns = coef_df.iloc[0]\n",
    "\n",
    "    # Drop the extra row with column labels\n",
    "    coef_df=coef_df.drop(0)\n",
    "\n",
    "    # Set index to variable names \n",
    "    coef_df = coef_df.set_index(coef_df.columns[0])\n",
    "\n",
    "    # Change datatype from object to float\n",
    "    coef_df = coef_df.astype(float)\n",
    "\n",
    "    # Get errors; (coef - lower bound of conf interval)\n",
    "    errors = coef_df['coef'] - coef_df['[0.025']\n",
    "    \n",
    "    # Append errors column to dataframe\n",
    "    coef_df['errors'] = errors\n",
    "\n",
    "    # Drop the constant for plotting\n",
    "    coef_df = coef_df.drop(['const'])\n",
    "\n",
    "    # Sort values by coef ascending\n",
    "    coef_df = coef_df.sort_values(by=['coef'])\n",
    "\n",
    "    ### Plot Coefficients ###\n",
    "\n",
    "    # x-labels\n",
    "    variables = list(coef_df.index.values)\n",
    "    \n",
    "    # Add variables column to dataframe\n",
    "    coef_df['variables'] = variables\n",
    "    \n",
    "    # Set sns plot style back to 'poster'\n",
    "    # This will make bars wide on plot\n",
    "    sns.set_context(\"poster\")\n",
    "\n",
    "    # Define figure, axes, and plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    # Error bars for 95% confidence interval\n",
    "    # Can increase capsize to add whiskers\n",
    "    coef_df.plot(x='variables', y='coef', kind='bar',\n",
    "                 ax=ax, color='none', fontsize=22, \n",
    "                 ecolor='steelblue',capsize=0,\n",
    "                 yerr='errors', legend=False)\n",
    "    \n",
    "    # Set title & labels\n",
    "    plt.title('Coefficients of Features w/ 95% Confidence Intervals',fontsize=30)\n",
    "    ax.set_ylabel('Coefficients',fontsize=22)\n",
    "    ax.set_xlabel('',fontsize=22)\n",
    "    \n",
    "    # Coefficients\n",
    "    ax.scatter(x=pd.np.arange(coef_df.shape[0]), \n",
    "               marker='o', s=80, \n",
    "               y=coef_df['coef'], color='steelblue')\n",
    "    \n",
    "    # Line to define zero on the y-axis\n",
    "    ax.axhline(y=0, linestyle='--', color='red', linewidth=1)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d45f5-e596-4b9e-ae29-8b215a7ec076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the folders \n",
    "data_folder = \"../data/\"\n",
    "analysis_results_folder = \"../results/\"\n",
    "plots_folders = \"../plots\"\n",
    "\n",
    "# Filenames\n",
    "dataset_clean_filename = 'cleaned_dataset_per_subject.csv'\n",
    "\n",
    "dataset_news_full_filename = 'cleaned_dataset_per_news.csv'\n",
    "\n",
    "df_subject = pd.read_csv('{}{}'.format(data_folder, dataset_clean_filename))\n",
    "df_news = pd.read_csv('{}{}'.format(data_folder, dataset_news_full_filename))\n",
    "# Fix some variable for later analysis\n",
    "#df_news['answer'] = df_news['answer'].astype('category') # Transform answer as factor\n",
    "#df_news['id_sondea'] = df_news['id_sondea'].astype(str) # Transform id_sondea as str for transforming into category later\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc46903-9f7d-4f36-93b5-77a5a36e970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08853c27-b7a9-41b2-a841-2ecde0bfcb25",
   "metadata": {},
   "source": [
    "# Plots and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc1f60-3d69-4497-b3a7-406d13f280fb",
   "metadata": {},
   "source": [
    "## Type news - Right/Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0b07a-803c-4da8-8093-c99c2b54b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_type_news_answer = pd.crosstab(df_news['type_news'], df_news['answer'])\n",
    "count_type_news_answer.to_csv('./tables/type_news_answer_count.csv', index=False)\n",
    "count_type_news_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d2ea9-42eb-4459-9760-eac95d3c505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "x_labels = ['Misinformation', 'Legitimate information']\n",
    "\n",
    "sns.countplot(hue=\"answer\", x='type_news',  data=df_news, ax=ax,)\n",
    "\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set(xlabel='Type of news', ylabel='Count of answer')\n",
    "\n",
    "ax.yaxis.grid(True, clip_on=False)                                                 \n",
    "sns.despine(left=True, bottom=True)    \n",
    "\n",
    "fig.savefig('./plots/right_wrong_per_type.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/right_wrong_per_type.png', format='png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67a2ae-ea3a-45f4-ba1c-3c7321481cc0",
   "metadata": {},
   "source": [
    "A Chisquare test did not show influence of the nature of the news and the capacity for the subjects to correctly identify them X^2(1, N=1680)= 2.54, p=.11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47da612-ea1f-4a32-a85d-f82b87273bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_news_chisquare = chisq_posthoc_corrected(pd.crosstab(df_news['type_news'], df_news['answer']))\n",
    "type_news_chisquare.to_csv('./tables/type_news_chisquare.csv', index=False)\n",
    "type_news_chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db1cd7-5108-499a-a977-552a7980376f",
   "metadata": {},
   "source": [
    "## News titles - Right/ Wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac389a6-5a5e-497a-8ec9-a01b111e0844",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_news_titles = pd.crosstab(df_news['news_title'], df_news['answer'])\n",
    "crosstab_news_titles.to_csv('./tables/news_titles_right_wrong_count.csv', index=True)\n",
    "crosstab_news_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b3e3e-5a21-4ebf-bdf5-8d464581d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_plot = df_news[['answer', 'news_title', 'type_news']].value_counts().to_frame().reset_index()#.rename(columns={'Answer', 'News Title', 'Type of News', 'Count'})\n",
    "fig, axes = plt.subplots(1,2,figsize=(20,10))\n",
    "axes = axes.flatten()\n",
    "type_news = ['fake_news', 'true_news']\n",
    "for type_ ,ax in zip(type_news,axes):\n",
    "    #to_plot = df_news[df_news.type_news==type_][['news_title','answer']].value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    to_plot = df_news[df_news.type_news==type_][['answer', 'news_title', 'type_news']].value_counts().to_frame().reset_index()\n",
    "    \n",
    "    \n",
    "    labels = to_plot['news_title'].unique()\n",
    "    labels = [ '\\n'.join(wrap(l, 30)) for l in labels ]\n",
    "    count_right = to_plot[to_plot['answer'] == 'Right'][0]\n",
    "    count_wrong = to_plot[to_plot['answer'] == 'Wrong'][0]\n",
    "    width = 0.7\n",
    "\n",
    "    ax.barh(labels, count_right, width, label='Right')\n",
    "    ax.barh(labels, count_wrong, width, left=count_right,\n",
    "           label='Wrong')\n",
    "    ax.set_xlabel(\"Count of answer\", fontsize='x-large')\n",
    "    ax.set_ylabel('', fontsize='x-large') \n",
    "    \n",
    "    if type_ == 'fake_news':\n",
    "        title_plot = 'Misinformation'\n",
    "    elif type_ == 'true_news':\n",
    "        title_plot = 'Legitimate information'\n",
    "    else:\n",
    "        raise\n",
    "    ax.set_title(title_plot, fontdict={'fontsize': 'xx-large'})\n",
    "    ax.yaxis.grid(False)                                                 \n",
    "\n",
    "    plt.xticks(fontsize='large')\n",
    "    plt.yticks(fontsize='large')\n",
    "plt.legend()\n",
    "fig.subplots_adjust(wspace=.5)    \n",
    "fig.savefig('./plots/right_wrong_per_news.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/right_wrong_per_news.png', format='png', bbox_inches='tight')    \n",
    "    \n",
    "    #df.unstack().plot.barh(ax=ax, stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443fc9e-9c17-47d4-b594-5710b648d88f",
   "metadata": {},
   "source": [
    "There is difference between the news about receiving a right or a wrong answers, some news got a fairly balanced answers, while some are more imbalanced in one way or the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595659f2-656a-4aec-8e80-5c20b56ae931",
   "metadata": {},
   "source": [
    "## Socio-demographic information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c058b63-8fb9-4677-ba41-f731b9236b82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1a8ed-6764-4fc4-89b9-e3c8b89dbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_count = df_subject['Gender'].value_counts().to_frame().reset_index().rename(columns={'index': 'Gender', 'Gender': \"Count\"})\n",
    "#gender_count = gender_count.replace({\"Femenino\": \"Female\", 'Masculino': \"Male\"})\n",
    "gender_count.to_csv('./tables/gender_counts.csv', index=False)\n",
    "gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d360198-7d67-4e85-9a3d-ec6d9e2bb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(gender_count['Gender'], gender_count['Count'])\n",
    "\n",
    "ax.set_xlabel(\"Gender\", fontsize='large')\n",
    "ax.set_ylabel('Count', fontsize='large') \n",
    "\n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle('Counts for Gender', fontsize='xx-large')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig.savefig('./plots/gender_count.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/gender_count.png', format='png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed646b-a564-4df0-9cc4-6929ad630784",
   "metadata": {},
   "source": [
    "### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe132ed-4817-4820-8b1b-f117ced07a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_count = df_subject['Education'].value_counts().to_frame().reset_index().rename(columns={'index': 'Education', 'Education': \"Count\"})\n",
    "#.replace({\"University_studies\": \"University level\", 'No_university_studies': \"No University level\"})\n",
    "gender_count.to_csv('./tables/education_counts.csv', index=False)\n",
    "gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89671702-7958-4565-b90c-324734dc6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(gender_count['Education'], gender_count['Count'])\n",
    "\n",
    "ax.set_xlabel(\"Education level\", fontsize='large')\n",
    "ax.set_ylabel('Count', fontsize='large') \n",
    "\n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle('Counts for education level', fontsize='xx-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('./plots/education_counts.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/education_counts.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb13fb-7f8e-4c79-869c-9748dbc15689",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_count2 = df_subject['Education2'].value_counts().to_frame().reset_index().rename(columns={'index': 'Education', 'Education2': \"Count\"})\n",
    "#.replace({\"University_studies\": \"University level\", 'No_university_studies': \"No University level\"})\n",
    "\n",
    "\n",
    "sorter = [\"Secondary\", \"College\", \"University\"]\n",
    "gender_count2.Education = gender_count2.Education.astype(\"category\")\n",
    "\n",
    "gender_count2.Education.cat.set_categories(sorter, inplace=True)\n",
    "gender_count2 = gender_count2.sort_values('Education')\n",
    "gender_count2.to_csv('./tables/education2_counts.csv', index=False)\n",
    "gender_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4dc0a9-80d0-405d-a346-0e00f1ff603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(gender_count2['Education'], gender_count2['Count'])\n",
    "\n",
    "ax.set_xlabel(\"Education level\", fontsize='large')\n",
    "ax.set_ylabel('Count', fontsize='large') \n",
    "\n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle('Counts for education level', fontsize='xx-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('./plots/education2_counts.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/education2_counts.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92035989-48a1-45f7-ba19-0ee65747107a",
   "metadata": {},
   "source": [
    "### Age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f974553-96b5-42eb-bce5-c90a144df19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_count = df_subject['Age'].value_counts().to_frame().reset_index().rename(columns={'index': 'Age', 'Age': \"Count\"})\n",
    "#gender_count = gender_count.replace({\"University_studies\": \"University level\", 'No_university_studies': \"No University level\"})\n",
    "sorter = [\"<=18-34\", \"35-54\", \">55\"]\n",
    "gender_count.Age = gender_count.Age.astype(\"category\")\n",
    "\n",
    "gender_count.Age.cat.set_categories(sorter, inplace=True)\n",
    "gender_count = gender_count.sort_values('Age')\n",
    "gender_count.to_csv('./tables/age_counts.csv', index=False)\n",
    "gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b89dd-9dae-4a49-b2b4-1943a9203517",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(gender_count['Age'], gender_count['Count'])\n",
    "\n",
    "ax.set_xlabel(\"Age\", fontsize='large')\n",
    "ax.set_ylabel('Count', fontsize='large') \n",
    "\n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle('Counts for age', fontsize='xx-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('./plots/age_counts.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/age_counts.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85549f46-d23b-4b96-af6b-f7a9e7197684",
   "metadata": {},
   "source": [
    "### Technological knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39caf91f-aac5-4dd5-8f15-5abd1d80f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_count = df_subject['Technological'].value_counts().to_frame().reset_index().rename(columns={'index': 'Technological knowledge', 'Technological': \"Count\"})\n",
    "#gender_count = gender_count.replace({\"Avanzada\": \"Advanced\", 'Media': \"Intermediary\", \"Básica\": \"Basic\"})\n",
    "\n",
    "\n",
    "sorter = [\"Basic\", \"Intermediate\", \"Advanced\"]\n",
    "gender_count[\"Technological knowledge\"] = gender_count[\"Technological knowledge\"].astype(\"category\")\n",
    "\n",
    "gender_count[\"Technological knowledge\"].cat.set_categories(sorter, inplace=True)\n",
    "gender_count = gender_count.sort_values(\"Technological knowledge\")\n",
    "\n",
    "\n",
    "gender_count.to_csv('./tables/tech_level_counts.csv', index=False)\n",
    "gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdab327-4603-4235-8237-1e9dcfbe2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(gender_count['Technological knowledge'], gender_count['Count'])\n",
    "\n",
    "ax.set_xlabel(\"Technological knowledge\", fontsize='large')\n",
    "ax.set_ylabel('Count', fontsize='large') \n",
    "\n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle('Counts for Technological knowledge', fontsize='xx-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('./plots/tech_level_counts.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/tech_level_counts.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c589c8-5bbe-4ae7-be4e-be95edbbab78",
   "metadata": {},
   "source": [
    "### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4764abe-573e-401e-969e-e8fe70aaa6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_count = df_subject['Religion'].value_counts().to_frame().reset_index().rename(columns={'index': 'Religion', 'Religion': \"Count\"})\n",
    "#gender_count = gender_count.replace({\"University_studies\": \"University level\", 'No_university_studies': \"No University level\"})\n",
    "gender_count.to_csv('./tables/religion_counts.csv', index=False)\n",
    "gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa66ddf-2fca-453d-addd-f87e60a8a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(gender_count['Religion'], gender_count['Count'])\n",
    "\n",
    "ax.set_xlabel(\"Religion\", fontsize='large')\n",
    "ax.set_ylabel('Count', fontsize='large') \n",
    "\n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle('Counts for Religous vs No Religious', fontsize='xx-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('./plots/religion_counts.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/religion_counts.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a162a-9626-49f3-bea3-d9a71300f736",
   "metadata": {},
   "source": [
    "### Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480fad8-5d8e-400f-99ac-76249a1d1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_count = df_subject['Political'].value_counts().to_frame().reset_index().rename(columns={'index': 'Political alignment', 'Political': \"Count\"})\n",
    "#gender_count = gender_count.replace({\"Izquierda\": \"Left\", 'Derecha': \"Right\", \"Centro\": \"Centre\"})\n",
    "\n",
    "\n",
    "sorter = [\"Left\", \"Centre\", \"Right\"]\n",
    "gender_count[\"Political alignment\"] = gender_count[\"Political alignment\"].astype(\"category\")\n",
    "\n",
    "gender_count[\"Political alignment\"].cat.set_categories(sorter, inplace=True)\n",
    "gender_count = gender_count.sort_values(\"Political alignment\")\n",
    "\n",
    "gender_count.to_csv('./tables/politic_counts.csv', index=False)\n",
    "gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a839943-3749-47c7-b39e-a56e1ac7247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(gender_count[\"Political alignment\"], gender_count['Count'])\n",
    "\n",
    "ax.set_xlabel(\"Political alignment\", fontsize='large')\n",
    "ax.set_ylabel('Count', fontsize='large') \n",
    "\n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle('Counts for \"Political alignment\"', fontsize='xx-large')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('./plots/politic_counts.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/politic_counts.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bc79e-34ea-40e8-bcc3-d62814ece7c4",
   "metadata": {},
   "source": [
    "## Justifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f000f1-0e6e-4e52-b67d-66ac81ae0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Justification columns\n",
    "\n",
    "\n",
    "var_just_fake = [\"Previously_read_debunked\",\n",
    "                 \"Source_unknown\",\n",
    "                 \"Media_unreliable\",\n",
    "                 \"Cited_sources_unknown\",\n",
    "                 \"Cited_sources_unreliable\",\n",
    "                 \"Without_sources\",\n",
    "                 \"Unprofessional_style\",\n",
    "                 \"No_coherent\",\n",
    "                 \"Headline_sensationalist\",\n",
    "                 \"Image_sensationalist\",\n",
    "                 \"Different_belief\",\n",
    "                 \"Different_ideology\",\n",
    "                 \"Other\"]\n",
    "\n",
    "var_just_true = [\"Previously_read_the_information\",\n",
    "                 \"Known_media\",\n",
    "                 \"Reliable_media\",\n",
    "                 \"Source_known\",\n",
    "                 \"Source_Reliable\",\n",
    "                 \"Professional_style\",\n",
    "                 \"Coherent\",\n",
    "                 \"Same_belief\",\n",
    "                 \"Same_ideology\",\n",
    "                 \"Other\"]\n",
    "\n",
    "## Creating mask to sample only when Participants were presented the Justification right and Justification wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf006ce-274d-4454-9848-88e7bf08f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting the different justifications \n",
    "df_new_to_plot_right = pd.melt(df_news, id_vars= ['answer', 'type_news', 'id_sondea', 'news_title'], value_vars=[*var_just_true ])\n",
    "#Rename the justification to be the same \n",
    "\n",
    "#df_new_to_plot_right['variable'] = df_new_to_plot_right['variable'].str[4:]\n",
    "\n",
    "mask_justification_right = (((df_new_to_plot_right['type_news'] == 'true_news') & (df_new_to_plot_right['answer'] == 'Right')) | ((df_new_to_plot_right['type_news'] == 'fake_news') & (df_new_to_plot_right['answer'] == 'Wrong')))\n",
    "df_new_to_plot_right = df_new_to_plot_right[mask_justification_right].copy()\n",
    "\n",
    "# Replacing the answer 'otro' by True rather than keeping the name\n",
    "special_answers = ~df_new_to_plot_right.value.isin([True, False, np.NaN])\n",
    "df_new_to_plot_right.loc[special_answers, 'value'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134933ac-aab4-43d4-bce2-6c6e26138a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = df_new_to_plot_right.groupby(by=['variable', 'answer', 'type_news'])['value'].sum().to_frame().reset_index()#.rename(columns=['Justification', 'answer', 'type_news', 'count'])\n",
    "# Filtering only the justification right\n",
    "mask_justification_right = (((to_plot['type_news'] == 'true_news') & (to_plot['answer'] == 'Right')) | ((to_plot['type_news'] == 'fake_news') & (to_plot['answer'] == 'Wrong')))\n",
    "to_plot = to_plot[mask_justification_right]\n",
    "# Reorder plot based on the right answer\n",
    "to_plot = to_plot.sort_values(by=['answer', 'value'])\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c8fef-295e-4add-bd45-ae49cc2b1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting the different justifications \n",
    "df_new_to_plot_wrong = pd.melt(df_news, id_vars= ['answer', 'type_news', 'id_sondea', 'news_title'], value_vars=[*var_just_fake ])\n",
    "#Rename the justification to be the same \n",
    "\n",
    "# Replacing the answer 'otro' by True rather than keeping the name\n",
    "special_answers = ~df_new_to_plot_wrong.value.isin([True, False, np.NaN])\n",
    "df_new_to_plot_wrong.loc[special_answers, 'value'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b3a12-ffc2-4924-9648-c26098cf0ac6",
   "metadata": {},
   "source": [
    "### Justifications when the subject think it is misinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c7ba5-0a78-4108-8a2d-5854e6ad0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = df_new_to_plot_wrong.groupby(by=['variable', 'answer', 'type_news'])['value'].sum().to_frame().reset_index()#.rename(columns=['Justification', 'answer', 'type_news', 'count'])\n",
    "# Filtering only the justification right\n",
    "mask_justification_wrong = (((to_plot['type_news'] == 'true_news') & (to_plot['answer'] == 'Wrong')) | ((to_plot['type_news'] == 'fake_news') & (to_plot['answer'] == 'Right')))\n",
    "to_plot = to_plot[mask_justification_wrong]\n",
    "# Reorder plot based on the right answer\n",
    "to_plot = to_plot.sort_values(by=['answer', 'value'])\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba61f0-284b-4f83-8a52-4c55f65008af",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_plot['variable'].unique()\n",
    "count_right = to_plot[to_plot['type_news'] == 'fake_news']['value']\n",
    "count_wrong = to_plot[to_plot['type_news'] == 'true_news']['value']\n",
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(labels, count_right, width, label='Right')\n",
    "ax.barh(labels, count_wrong, width, left=count_right,\n",
    "      label='Wrong')\n",
    "ax.set_xlabel(\"Count of answers\", fontsize='large')\n",
    "ax.set_ylabel('Justification', fontsize='large') \n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle('Justification when Subject thinks it is misinformation', fontsize=16)\n",
    "fig.savefig('./plots/justification_fake_news.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/justification_fake_news.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a940cd-83d8-4a29-8f32-42c6e6685a3a",
   "metadata": {},
   "source": [
    "### Justifications when the subject thinks it is a True news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce30486-93cc-4796-aa60-35fb790fb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = df_new_to_plot_right.groupby(by=['variable', 'answer', 'type_news'])['value'].sum().to_frame().reset_index()#.rename(columns=['Justification', 'answer', 'type_news', 'count'])\n",
    "# Filtering only the justification right\n",
    "mask_justification_wrong = (((to_plot['type_news'] == 'true_news') & (to_plot['answer'] == 'Right')) | ((to_plot['type_news'] == 'fake_news') & (to_plot['answer'] == 'Wrong')))\n",
    "to_plot = to_plot[mask_justification_wrong]\n",
    "# Reorder plot based on the right answer\n",
    "to_plot = to_plot.sort_values(by=['answer', 'value'])\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861ff88-f291-4d86-85a6-4ebc594f4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_plot['variable'].unique()\n",
    "count_right = to_plot[to_plot['type_news'] == 'fake_news']['value']\n",
    "count_wrong = to_plot[to_plot['type_news'] == 'true_news']['value']\n",
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(labels, count_right, width, label='Wrong')\n",
    "ax.barh(labels, count_wrong, width, left=count_right,\n",
    "      label='Right')\n",
    "ax.set_xlabel(\"Count of answers\", fontsize='large')\n",
    "ax.set_ylabel('Justification', fontsize='large') \n",
    "\n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.legend()\n",
    "#plt.legend(labels=[\"Right answer\",\"Wrong answer\"], fontsize='medium')\n",
    "\n",
    "plt.suptitle('Justification when Subject thinks it is legitimate information', fontsize=16)\n",
    "fig.savefig('./plots/justification_right_news.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/justification_right_news.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ebc68-b672-451c-927c-cc1542d749f9",
   "metadata": {},
   "source": [
    "### Justification, people getting wrong on Misinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc69c73-48ab-4cee-a614-623920cf6653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only the justification right\n",
    "mask_justification_fake_wrong = (((df_new_to_plot_right['type_news'] == 'fake_news') & (df_new_to_plot_right['answer'] == 'Wrong')))\n",
    "to_plot = df_new_to_plot_right[mask_justification_fake_wrong]\n",
    "\n",
    "to_plot = to_plot.groupby(by=['variable', 'answer', 'type_news'])['value'].sum().to_frame().reset_index()#.rename(columns=['Justification', 'answer', 'type_news', 'count'])\n",
    "\n",
    "# Reorder plot based on the right answer\n",
    "to_plot = to_plot.sort_values(by=['answer', 'value']).drop(columns=['answer', 'type_news'])\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bb07b-4336-4e71-bd7c-af20d30d7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "labels = to_plot['variable']\n",
    "counts = to_plot['value']\n",
    "ax.barh(labels, counts, width, label='Wrong')\n",
    "\n",
    "ax.set_xlabel(\"Count of answers\", fontsize='large')\n",
    "ax.set_ylabel('Justification', fontsize='large') \n",
    "\n",
    "\n",
    "#ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "#plt.legend(labels=[\"Right answer\",\"Wrong answer\"], fontsize='medium')\n",
    "\n",
    "plt.suptitle('Justification when subject consider a Misinformation as Legitimate', fontsize=16)\n",
    "\n",
    "#plt.tight_layout()\n",
    "\n",
    "fig.savefig('./plots/justification_fake_wrong.svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/justification_fake_wrong.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb810ccd-64d1-4e77-a568-0024dc692261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_to_plot_right[mask_justification_fake_wrong]['id_sondea'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d198e-50ac-46db-a67c-1b62d5bbc767",
   "metadata": {},
   "source": [
    " ### Justification, people getting right on Legitimate information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea238f47-10dd-4478-9666-74604e90598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only the justification right\n",
    "mask_justification_true_right = (((df_new_to_plot_right['type_news'] == 'true_news') & (df_new_to_plot_right['answer'] == 'Right')))\n",
    "to_plot = df_new_to_plot_right[mask_justification_true_right]\n",
    "\n",
    "to_plot = to_plot.groupby(by=['variable', 'answer', 'type_news'])['value'].sum().to_frame().reset_index()#.rename(columns=['Justification', 'answer', 'type_news', 'count'])\n",
    "\n",
    "# Reorder plot based on the right answer\n",
    "to_plot = to_plot.sort_values(by=['answer', 'value']).drop(columns=['answer', 'type_news'])\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0a622-9051-434a-aadd-f86dfcba5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "labels = to_plot['variable']\n",
    "counts = to_plot['value']\n",
    "ax.barh(labels, counts, width, label='Wrong')\n",
    "\n",
    "ax.set_xlabel(\"Count of answers\", fontsize='large')\n",
    "ax.set_ylabel('Justification', fontsize='large') \n",
    "\n",
    "\n",
    "#ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "#plt.legend(labels=[\"Right answer\",\"Wrong answer\"], fontsize='medium')\n",
    "\n",
    "plt.suptitle('Justification when subject consider a Legitimate as Legitimate', fontsize=16)\n",
    "\n",
    "#plt.tight_layout()\n",
    "\n",
    "fig.savefig('./plots/justification_true_right.svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/justification_true_right.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51ac16-6906-461c-96a5-5bbed548110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_to_plot_right[mask_justification_true_right]['id_sondea'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2fd26-7d0f-4790-a055-d2fe230e87cb",
   "metadata": {},
   "source": [
    "### Justification, people getting Right on Misinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e81049-a092-4e49-9fb8-f5debfe94b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only the justification right\n",
    "mask_justification_fake_right = (((df_new_to_plot_wrong['type_news'] == 'fake_news') & (df_new_to_plot_wrong['answer'] == 'Right')))\n",
    "to_plot = df_new_to_plot_wrong[mask_justification_fake_right]\n",
    "\n",
    "to_plot = to_plot.groupby(by=['variable', 'answer', 'type_news'])['value'].sum().to_frame().reset_index()#.rename(columns=['Justification', 'answer', 'type_news', 'count'])\n",
    "\n",
    "# Reorder plot based on the right answer\n",
    "to_plot = to_plot.sort_values(by=['answer', 'value']).drop(columns=['answer', 'type_news'])\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4efe5e8-9f3f-4926-946f-2fa4b1207c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "labels = to_plot['variable']\n",
    "counts = to_plot['value']\n",
    "ax.barh(labels, counts, width, label='Wrong')\n",
    "\n",
    "ax.set_xlabel(\"Count of answers\", fontsize='large')\n",
    "ax.set_ylabel('Justification', fontsize='large') \n",
    "\n",
    "\n",
    "#ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "#plt.legend(labels=[\"Right answer\",\"Wrong answer\"], fontsize='medium')\n",
    "\n",
    "plt.suptitle('Justification when subject consider a Misinformation as Misinformation', fontsize=16)\n",
    "\n",
    "#plt.tight_layout()\n",
    "\n",
    "fig.savefig('./plots/justification_fake_right.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/justification_fake_right.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3c6c0-2799-42ef-b721-22cb3cb09919",
   "metadata": {},
   "source": [
    "### Justification, people getting Wrong on Misinformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad874b4b-81ba-477b-9da4-9e68ca4d52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only the justification right\n",
    "mask_justification_true_wrong = (((df_new_to_plot_wrong['type_news'] == 'true_news') & (df_new_to_plot_wrong['answer'] == 'Wrong')))\n",
    "to_plot = df_new_to_plot_wrong[mask_justification_true_wrong]\n",
    "\n",
    "to_plot = to_plot.groupby(by=['variable', 'answer', 'type_news'])['value'].sum().to_frame().reset_index()#.rename(columns=['Justification', 'answer', 'type_news', 'count'])\n",
    "\n",
    "# Reorder plot based on the right answer\n",
    "to_plot = to_plot.sort_values(by=['answer', 'value']).drop(columns=['answer', 'type_news'])\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11421d-a4e1-4eef-91e4-486fe964a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "labels = to_plot['variable']\n",
    "counts = to_plot['value']\n",
    "ax.barh(labels, counts, width, label='Wrong')\n",
    "\n",
    "ax.set_xlabel(\"Count of answers\", fontsize='large')\n",
    "ax.set_ylabel('Justification', fontsize='large') \n",
    "\n",
    "\n",
    "#ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "#plt.legend(labels=[\"Right answer\",\"Wrong answer\"], fontsize='medium')\n",
    "\n",
    "plt.suptitle('Justification when subject consider a Legitimate information as Misinformation', fontsize=16)\n",
    "\n",
    "#plt.tight_layout()\n",
    "\n",
    "fig.savefig('./plots/justification_true_wrong.svg', format='svg', bbox_inches='tight')\n",
    "fig.savefig('./plots/justification_true_wrong.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af9699-73de-47f8-bf35-3a85103141d5",
   "metadata": {},
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051342c9-b1d8-48b5-8b8c-26ac225c65c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_actions = ['share_friends_and_family', \n",
    "               'share_online', \n",
    "               'verify_source', \n",
    "               \"apply_learning\", \n",
    "               'no_action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561bd7c-e39f-4833-bc67-9994ece55d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting the different justifications \n",
    "df_new_to_plot_action = pd.melt(df_news, id_vars= ['answer', 'type_news', 'id_sondea', 'news_title'], value_vars=[*var_actions])\n",
    "#Rename the justification to be the same \n",
    "mask_action = (((df_new_to_plot_action['type_news'] == 'true_news') & (df_new_to_plot_action['answer'] == 'Right')) | ((df_new_to_plot_action['type_news'] == 'fake_news') & (df_new_to_plot_action['answer'] == 'Wrong')))\n",
    "df_new_to_plot_action_filtered = df_new_to_plot_action[mask_action].copy()\n",
    "#df_new_to_plot_right_filtered['variable'] = df_new_to_plot_right_filtered['variable'].str[4:]\n",
    "\n",
    "#df_new_to_plot_right['variable'] = np.where(df_new_to_plot_right['value']== 1, df_new_to_plot_right['variable'],np.NaN )\n",
    "df_new_to_plot_action_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2484cdf-7bfe-422e-887f-d4309bd0f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = df_new_to_plot_action_filtered.groupby(by=['variable', 'answer', 'type_news'])['value'].sum().to_frame().reset_index()#.rename(columns=['Justification', 'answer', 'type_news', 'count'])\n",
    "# Filtering only the justification TR or FW\n",
    "mask_action = (((to_plot['type_news'] == 'true_news') & (to_plot['answer'] == 'Right')) | ((to_plot['type_news'] == 'fake_news') & (to_plot['answer'] == 'Wrong')))\n",
    "\n",
    "to_plot = to_plot[mask_action].copy()\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6bb85-b06a-4016-99c3-95cd531ab6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_plot['variable'].unique()\n",
    "\n",
    "count_right = to_plot[to_plot['type_news'] == 'true_news']['value']\n",
    "count_wrong = to_plot[to_plot['type_news'] == 'fake_news']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1d880-a8ea-4854-9177-2794a0c73075",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = to_plot.sort_values(by=['answer', 'value'])\n",
    "labels = to_plot['variable'].unique()\n",
    "count_right = to_plot[to_plot['type_news'] == 'fake_news']['value']\n",
    "count_wrong = to_plot[to_plot['type_news'] == 'true_news']['value']\n",
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(labels, count_right, width, label='Right')\n",
    "ax.barh(labels, count_wrong, width, left=count_right,\n",
    "      label='Wrong')\n",
    "ax.set_xlabel(\"Count of answers\", fontsize='large')\n",
    "ax.set_ylabel('Actions', fontsize='large') \n",
    "\n",
    "ax.yaxis.grid(False)   \n",
    "ax.xaxis.grid(False)                                                 \n",
    "\n",
    "\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "\n",
    "\n",
    "#plt.legend(labels=[\"Right answer\",\"Wrong answer\"], fontsize='large')\n",
    "plt.legend()\n",
    "plt.suptitle('Actions when subject thinks it is legitimate information', fontsize=18)\n",
    "#plt.tight_layout()\n",
    "fig.savefig('./plots/action_true_news.svg', format='svg')\n",
    "fig.savefig('./plots/action_true_news.png', format='png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
